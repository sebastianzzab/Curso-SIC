{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Document classification with LSTM network (Binary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets.imdb import load_data, get_word_index       # Movie review data. \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "warnings.filterwarnings('ignore')                              # Turn the warnings off.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 3000                                        # Size of the vocabulary.\n",
    "(X_train, y_train), (X_test, y_test) = load_data(num_words = n_words)\n",
    "n_train_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the shapes.\n",
    "print(\"-\"*50)\n",
    "print(\"Training data X shape: {}\".format(X_train.shape))\n",
    "print(\"Training data y shape: {}\".format(y_train.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"Test data X shape: {}\".format(X_test.shape))\n",
    "print(\"Test data y shape: {}\".format(y_test.shape))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values of y = Number of categories of the newswires.\n",
    "n_cat = pd.Series(y_train).nunique()\n",
    "n_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out an observation (document) contained in X.\n",
    "# It is encoded as integers (indices).\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check for length of the first 100 documents.\n",
    "# We notice that the length is not uniform.\n",
    "print([len(a) for a in X_train[0:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dictionary to translate the indices.\n",
    "my_dict = get_word_index(path='imdb_word_index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the dictionary.\n",
    "# my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange the 'key' and 'value'.\n",
    "my_dict_inv = {v:k for k,v in my_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate each document.\n",
    "i_review = 10                                        # Document number that can be changed at will.\n",
    "review = list(pd.Series(X_train[i_review]).apply(lambda x: my_dict_inv[x]))\n",
    "print(' '.join(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding: newswire lengths are uniformly matched to maxlen.\n",
    "# Cut away if longer than maxlen and fill with 0s if shorter than maxlen.\n",
    "X_train = sequence.pad_sequences(X_train, maxlen = 100)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is already binary. Thus, there is no need to covert to the one-hot-encoding scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 50                    # Neurons within each memory cell.\n",
    "n_input = 100                     # Dimension of the embeding space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM network model.\n",
    "my_model = Sequential()\n",
    "my_model.add(Embedding(n_words, n_input))           # n_words = vocabulary size, n_input = dimension of the embedding space.\n",
    "my_model.add(LSTM(units=n_neurons, return_sequences=False, input_shape=(None, n_input), activation='tanh'))\n",
    "my_model.add(Dense(1, activation='sigmoid'))    # Binary output!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the summary.\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Define the optimizer and compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5                      # Number of epochs.\n",
    "batch_size = 50                    # Size of each batch.\n",
    "learn_rate = 0.002                 # learning rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and compilation.\n",
    "my_optimizer=Adam(lr=learn_rate)\n",
    "my_model.compile(loss = \"binary_crossentropy\", optimizer = my_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Train the model and visualize the history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_summary = my_model.fit(X_train, y_train, epochs=n_epochs, batch_size = batch_size, validation_split=0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(my_summary.history['accuracy'], c=\"b\")\n",
    "plt.plot(my_summary.history['val_accuracy'], c=\"g\")\n",
    "plt.title('Training History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. Testing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = my_model.evaluate(X_test, y_test, verbose=0)[1]    \n",
    "print(\"Test Accuracy : {}\".format(np.round(ACC,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
